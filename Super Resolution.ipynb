{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#DATA.PY"
      ],
      "metadata": {
        "id": "AdBsEknr0Bg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRYiBGg__t8u",
        "outputId": "4164c246-d3d7-4dcf-fec6-3a085d8257a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HIdb5ygz0f0",
        "outputId": "6d2aae3f-8254-47df-9cf6-27fc93a9682c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 224, 224, 3) (8, 224, 224, 1)\n"
          ]
        }
      ],
      "source": [
        "#importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "#train_test_split is to spliting dataset in to train, test, vaid\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80 for training, 10 for validation, 10 for testing\n",
        "def load_data(path, split=0.1):\n",
        "\n",
        "  #loading image and mask from cvc-612\n",
        "  #glob is for geeting all the conent available in the file\n",
        "  #sorting used for arrange image with its repective mask \n",
        "  # path=\"/content/drive/MyDrive/pp1/PROJECT/PROJECT/CVC-612\"\n",
        "    images = sorted(glob(os.path.join(path, \"/content/drive/MyDrive/images/*\")))\n",
        "    masks = sorted(glob(os.path.join(path, \"/content/drive/MyDrive/masks/*\")))\n",
        "\n",
        "#calculating the size of the iamges\n",
        "    total_size = len(images)\n",
        "#spliting images in to validsize and testsize    \n",
        "    valid_size = int(split * total_size)\n",
        "    test_size = int(split * total_size)\n",
        "    #print(total_size, valid_size, test_size)\n",
        "\n",
        "#spliting train data into train and validation\n",
        "    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n",
        "    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n",
        "#spliting training data into train and test\n",
        "    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n",
        "    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n",
        "    \n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "#reading the image and converting it to numpy array\n",
        "def read_image(path):\n",
        "    path = path.decode()#beacuse the path is in binary format\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)#geting images into RGB format\n",
        "    x = cv2.resize(x, (224, 224))\n",
        "    x = x/255.0 #normalizing the array so that its value will come between 0 and 1, it will help to reduce time.\n",
        "    # (256,256,3)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)#geting masks in grayscale\n",
        "    x = cv2.resize(x, (224, 224))\n",
        "    x = x/255.0 \n",
        "    #(256,256)\n",
        "    x = np.expand_dims(x, axis=-1)#expanding dimension of the numpy array.\n",
        "    #(256,256,1)\n",
        "    return x  \n",
        "\n",
        "def tf_parse(x, y):#The tf_parse function parses a single image and mask path.\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "#read_image and read_mask returning numpy array so we have to convert it in to tensorflow usable format\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
        "    x.set_shape([224, 224, 3])\n",
        "    y.set_shape([224, 224, 1])\n",
        "    return x, y\n",
        "#tf.data pipeline which takes a list of images, masks paths and the batch size.\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)#making batch of 8 images\n",
        "    dataset = dataset.repeat()\n",
        "    return  dataset\n",
        "\n",
        "if __name__ ==\"__main__\":\n",
        "    path=\"/content/drive/MyDrive\"\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y)= load_data(path) \n",
        "    \n",
        "    #for testing DATA.py\n",
        "    ds = tf_dataset(test_x,test_y)\n",
        "    for x,y in ds:\n",
        "      print(x.shape, y.shape)\n",
        "      break\n",
        "         "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL.PY"
      ],
      "metadata": {
        "id": "eo-gv8_c0KfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#x is the input num_filters is the number of filter we want to use in cn layer\n",
        "def conv_block(x, num_filters):\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)#using convolutional \n",
        "    x = BatchNormalization()(x)#batch normalization improves the performences\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_model():\n",
        "    size = 224 #input size\n",
        "    num_filters = [16, 32, 48, 64] #filters can go on like 128, 256\n",
        "    inputs = Input((size, size, 3))#setting the input layer (256, 256, 3)\n",
        "\n",
        "    skip_x = []#creating a list to store x's information\n",
        "    x = inputs\n",
        "    ## Encoder\n",
        "    for f in num_filters:\n",
        "        x = conv_block(x, f)\n",
        "        skip_x.append(x)#added append skip connection to the list\n",
        "        x = MaxPool2D((2, 2))(x)#performing 2D max pooling\n",
        "\n",
        "    ## Bridge\n",
        "    x = conv_block(x, num_filters[-1])#using last filter to join the decoder part with encoder\n",
        "\n",
        "    num_filters.reverse()#reversing the filters\n",
        "    skip_x.reverse()#reversing the skip connection\n",
        "    ## Decoder\n",
        "    for i, f in enumerate(num_filters):\n",
        "        x = UpSampling2D((2, 2))(x)#upsampling used to copies information from one pixel to another\n",
        "        xs = skip_x[i]#extracting information from the list\n",
        "        x = Concatenate()([x, xs])\n",
        "        x = conv_block(x, f)\n",
        "        #print(type(x))\n",
        "    ## Output\n",
        "    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
        "    x = Activation(\"sigmoid\")(x)#using sigmoid activation to get out in 0 and 1\n",
        "\n",
        "    return Model(inputs, x)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = build_model()\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfwfPh6J0OxB",
        "outputId": "0cf1b68f-63b6-42ea-e5ed-9a9324408c03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 224, 224, 16  448         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 224, 224, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 224, 224, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 224, 224, 16  2320        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 224, 224, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 112, 112, 32  4640        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 112, 112, 32  128        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 112, 112, 32  9248        ['activation_2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 112, 112, 32  128        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 56, 56, 48)   13872       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 56, 56, 48)  192         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 56, 56, 48)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 56, 56, 48)   20784       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 56, 56, 48)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 56, 56, 48)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 48)  0           ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 28, 28, 64)   27712       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 28, 28, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 28, 28, 64)   36928       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 28, 28, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 64)  0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 14, 14, 64)   36928       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 14, 14, 64)  256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 14, 14, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 14, 14, 64)   36928       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 14, 14, 64)  256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 14, 14, 64)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 28, 28, 64)   0           ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 28, 28, 128)  0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 28, 28, 64)   73792       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 28, 28, 64)  256         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 28, 28, 64)   36928       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 28, 28, 64)  256         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 64)  0           ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 56, 56, 112)  0           ['up_sampling2d_1[0][0]',        \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 56, 56, 48)   48432       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 56, 56, 48)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 56, 56, 48)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 56, 56, 48)   20784       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 56, 56, 48)  192         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 56, 56, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 112, 112, 48  0          ['activation_13[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 112, 112, 80  0           ['up_sampling2d_2[0][0]',        \n",
            "                                )                                 'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 112, 112, 32  23072       ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 112, 112, 32  128        ['conv2d_14[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 112, 112, 32  9248        ['activation_14[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 112, 112, 32  128        ['conv2d_15[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32  0          ['activation_15[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 224, 224, 48  0           ['up_sampling2d_3[0][0]',        \n",
            "                                )                                 'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 224, 224, 16  6928        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 224, 224, 16  64         ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 224, 224, 16  2320        ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 224, 224, 16  64         ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 224, 224, 1)  17          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 224, 224, 1)  0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 414,401\n",
            "Trainable params: 412,865\n",
            "Non-trainable params: 1,536\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAIN.PY"
      ],
      "metadata": {
        "id": "H6gX8eU40VjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gen_dataset_ops import shuffle_dataset\n",
        "from numpy.random.mtrand import shuffle\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "#from data import load_data, tf_dataset\n",
        "#from model import build_model\n",
        "\n",
        "def iou(y_true, y_pred):#intersection over union\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)#adding 1e-15 because union's value can be very small\n",
        "        x = x.astype(np.float32)#converting to float32\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  ##seeding \n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "    ## Dataset\n",
        "    path = \"/content/drive/MyDrive/\"\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
        "\n",
        "    ## Hyperparameters\n",
        "    batch = 8\n",
        "    lr = 1e-4\n",
        "    epochs = 50\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch)#training pipe line\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)#validating pipeline\n",
        "   \n",
        "   #building the u net model\n",
        "    model = build_model()\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(lr)\n",
        "    metrics = [\"acc\", Recall(), Precision(), iou]\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)#as we want to get loss in binary\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\"/content/drive/MyDrive/files/model.h5\"),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3),#if the validation loss does not reduce after 3 patience gactor will increase by 0.1\n",
        "        CSVLogger(\"/content/drive/MyDrive/files/data.csv\"),\n",
        "        TensorBoard(),\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)#to avoid overfitting\n",
        "    ]\n",
        "\n",
        "    train_steps = len(train_x)//batch#defining number of batches in train_x\n",
        "    valid_steps = len(valid_x)//batch#defining number of batches in valid_x\n",
        "\n",
        "    if len(train_x) % batch != 0:#if batch=0 implementing train_steps by 1\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch != 0:#if batch=0 implementing valid_steps by 1\n",
        "        valid_steps += 1\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks\n",
        "        #shuffle_dataset = False\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHCwddxm0T52",
        "outputId": "9c76e8fe-c5fe-4776-e375-2b4ced189d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 198s 5s/step - loss: 0.6045 - acc: 0.6814 - recall_42: 0.6497 - precision_42: 0.2960 - iou: 0.1703 - val_loss: 0.6401 - val_acc: 0.8293 - val_recall_42: 0.0434 - val_precision_42: 0.3957 - val_iou: 0.1361 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 190s 5s/step - loss: 0.5109 - acc: 0.7615 - recall_42: 0.6748 - precision_42: 0.3834 - iou: 0.1953 - val_loss: 0.5562 - val_acc: 0.8329 - val_recall_42: 2.0006e-04 - val_precision_42: 0.1134 - val_iou: 0.1282 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 188s 5s/step - loss: 0.4511 - acc: 0.8134 - recall_42: 0.6614 - precision_42: 0.4657 - iou: 0.2146 - val_loss: 0.5065 - val_acc: 0.8331 - val_recall_42: 0.0000e+00 - val_precision_42: 0.0000e+00 - val_iou: 0.1197 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 191s 5s/step - loss: 0.4057 - acc: 0.8532 - recall_42: 0.6508 - precision_42: 0.5610 - iou: 0.2373 - val_loss: 0.4770 - val_acc: 0.8331 - val_recall_42: 8.6593e-05 - val_precision_42: 0.2636 - val_iou: 0.1104 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 187s 5s/step - loss: 0.3661 - acc: 0.8835 - recall_42: 0.6520 - precision_42: 0.6650 - iou: 0.2637 - val_loss: 0.4629 - val_acc: 0.8331 - val_recall_42: 0.0000e+00 - val_precision_42: 0.0000e+00 - val_iou: 0.1001 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 188s 5s/step - loss: 0.3307 - acc: 0.9062 - recall_42: 0.6768 - precision_42: 0.7581 - iou: 0.2914 - val_loss: 0.4594 - val_acc: 0.8331 - val_recall_42: 0.0000e+00 - val_precision_42: 0.0000e+00 - val_iou: 0.0932 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 189s 5s/step - loss: 0.3016 - acc: 0.9215 - recall_42: 0.7137 - precision_42: 0.8178 - iou: 0.3178 - val_loss: 0.4547 - val_acc: 0.8327 - val_recall_42: 3.5533e-04 - val_precision_42: 0.1150 - val_iou: 0.0919 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 186s 5s/step - loss: 0.2809 - acc: 0.9295 - recall_42: 0.7401 - precision_42: 0.8444 - iou: 0.3393 - val_loss: 0.4466 - val_acc: 0.8296 - val_recall_42: 0.0193 - val_precision_42: 0.3271 - val_iou: 0.1003 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 190s 5s/step - loss: 0.2749 - acc: 0.9270 - recall_42: 0.7297 - precision_42: 0.8370 - iou: 0.3458 - val_loss: 0.4516 - val_acc: 0.8190 - val_recall_42: 0.0949 - val_precision_42: 0.3540 - val_iou: 0.1206 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 194s 5s/step - loss: 0.2644 - acc: 0.9295 - recall_42: 0.7367 - precision_42: 0.8451 - iou: 0.3561 - val_loss: 0.4309 - val_acc: 0.8318 - val_recall_42: 0.0634 - val_precision_42: 0.4836 - val_iou: 0.1150 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 188s 5s/step - loss: 0.2450 - acc: 0.9389 - recall_42: 0.7723 - precision_42: 0.8742 - iou: 0.3780 - val_loss: 0.4363 - val_acc: 0.8316 - val_recall_42: 0.0465 - val_precision_42: 0.4649 - val_iou: 0.1043 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 189s 5s/step - loss: 0.2277 - acc: 0.9476 - recall_42: 0.8011 - precision_42: 0.9029 - iou: 0.3989 - val_loss: 0.4354 - val_acc: 0.8296 - val_recall_42: 0.1101 - val_precision_42: 0.4689 - val_iou: 0.1244 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 187s 5s/step - loss: 0.2185 - acc: 0.9494 - recall_42: 0.8183 - precision_42: 0.8996 - iou: 0.4137 - val_loss: 0.4391 - val_acc: 0.8269 - val_recall_42: 0.1125 - val_precision_42: 0.4417 - val_iou: 0.1240 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 186s 5s/step - loss: 0.2103 - acc: 0.9531 - recall_42: 0.8242 - precision_42: 0.9165 - iou: 0.4226 - val_loss: 0.3790 - val_acc: 0.8536 - val_recall_42: 0.2238 - val_precision_42: 0.7074 - val_iou: 0.1757 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 189s 5s/step - loss: 0.1997 - acc: 0.9594 - recall_42: 0.8494 - precision_42: 0.9348 - iou: 0.4369 - val_loss: 0.3676 - val_acc: 0.8588 - val_recall_42: 0.2933 - val_precision_42: 0.6968 - val_iou: 0.1988 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 190s 5s/step - loss: 0.1961 - acc: 0.9614 - recall_42: 0.8584 - precision_42: 0.9395 - iou: 0.4419 - val_loss: 0.3602 - val_acc: 0.8638 - val_recall_42: 0.3547 - val_precision_42: 0.6938 - val_iou: 0.2180 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 190s 5s/step - loss: 0.1937 - acc: 0.9626 - recall_42: 0.8646 - precision_42: 0.9416 - iou: 0.4455 - val_loss: 0.3543 - val_acc: 0.8671 - val_recall_42: 0.4062 - val_precision_42: 0.6855 - val_iou: 0.2352 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 188s 5s/step - loss: 0.1916 - acc: 0.9635 - recall_42: 0.8694 - precision_42: 0.9432 - iou: 0.4487 - val_loss: 0.3521 - val_acc: 0.8678 - val_recall_42: 0.4348 - val_precision_42: 0.6753 - val_iou: 0.2448 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 191s 5s/step - loss: 0.1898 - acc: 0.9643 - recall_42: 0.8736 - precision_42: 0.9446 - iou: 0.4516 - val_loss: 0.3520 - val_acc: 0.8672 - val_recall_42: 0.4539 - val_precision_42: 0.6630 - val_iou: 0.2506 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 188s 5s/step - loss: 0.1880 - acc: 0.9650 - recall_42: 0.8773 - precision_42: 0.9459 - iou: 0.4544 - val_loss: 0.3529 - val_acc: 0.8660 - val_recall_42: 0.4616 - val_precision_42: 0.6532 - val_iou: 0.2536 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 194s 5s/step - loss: 0.1864 - acc: 0.9657 - recall_42: 0.8808 - precision_42: 0.9471 - iou: 0.4570 - val_loss: 0.3545 - val_acc: 0.8650 - val_recall_42: 0.4646 - val_precision_42: 0.6466 - val_iou: 0.2550 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 187s 5s/step - loss: 0.1846 - acc: 0.9667 - recall_42: 0.8843 - precision_42: 0.9496 - iou: 0.4595 - val_loss: 0.3545 - val_acc: 0.8646 - val_recall_42: 0.4606 - val_precision_42: 0.6461 - val_iou: 0.2543 - lr: 1.0000e-06\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 194s 5s/step - loss: 0.1844 - acc: 0.9667 - recall_42: 0.8849 - precision_42: 0.9497 - iou: 0.4598 - val_loss: 0.3550 - val_acc: 0.8641 - val_recall_42: 0.4623 - val_precision_42: 0.6432 - val_iou: 0.2550 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 187s 5s/step - loss: 0.1842 - acc: 0.9668 - recall_42: 0.8853 - precision_42: 0.9498 - iou: 0.4601 - val_loss: 0.3555 - val_acc: 0.8639 - val_recall_42: 0.4656 - val_precision_42: 0.6408 - val_iou: 0.2560 - lr: 1.0000e-06\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 187s 5s/step - loss: 0.1840 - acc: 0.9669 - recall_42: 0.8856 - precision_42: 0.9501 - iou: 0.4604 - val_loss: 0.3559 - val_acc: 0.8637 - val_recall_42: 0.4678 - val_precision_42: 0.6392 - val_iou: 0.2566 - lr: 1.0000e-07\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 193s 5s/step - loss: 0.1840 - acc: 0.9669 - recall_42: 0.8857 - precision_42: 0.9501 - iou: 0.4604 - val_loss: 0.3562 - val_acc: 0.8636 - val_recall_42: 0.4693 - val_precision_42: 0.6380 - val_iou: 0.2571 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 188s 5s/step - loss: 0.1840 - acc: 0.9669 - recall_42: 0.8857 - precision_42: 0.9501 - iou: 0.4604 - val_loss: 0.3564 - val_acc: 0.8634 - val_recall_42: 0.4702 - val_precision_42: 0.6370 - val_iou: 0.2574 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 187s 5s/step - loss: 0.1840 - acc: 0.9669 - recall_42: 0.8857 - precision_42: 0.9501 - iou: 0.4604 - val_loss: 0.3565 - val_acc: 0.8634 - val_recall_42: 0.4709 - val_precision_42: 0.6364 - val_iou: 0.2576 - lr: 1.0000e-08\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 193s 5s/step - loss: 0.1840 - acc: 0.9669 - recall_42: 0.8857 - precision_42: 0.9501 - iou: 0.4604 - val_loss: 0.3566 - val_acc: 0.8633 - val_recall_42: 0.4714 - val_precision_42: 0.6360 - val_iou: 0.2578 - lr: 1.0000e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PREDICT.PY"
      ],
      "metadata": {
        "id": "RBJnpxzg7t8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tqdm import tqdm\n",
        "#from data import load_data, tf_dataset\n",
        "#from train import iou\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (224, 224))\n",
        "    x = x/255.0\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (224, 224))\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x\n",
        "#for joining of image and predicted mask\n",
        "def mask_parse(mask):\n",
        "    mask = np.squeeze(mask)\n",
        "    mask = [mask, mask, mask]\n",
        "    mask = np.transpose(mask, (1, 2, 0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ## Dataset\n",
        "    path = \"/content/drive/MyDrive/\"\n",
        "    batch_size = 16\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
        "    print(len(train_x), len(valid_x), len(test_x))\n",
        "    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n",
        "\n",
        "    test_steps = len(test_x)//batch\n",
        "    if len(test_x) % batch != 0:\n",
        "        test_steps += 1\n",
        "#loading the u net model\n",
        "    with CustomObjectScope({'iou': iou}):\n",
        "        model = tf.keras.models.load_model(\"/content/drive/MyDrive/files/model.h5\")\n",
        "#evaluateing the model\n",
        "       # inputs=tf.Tensor(shape=(8,), dtype=str)\n",
        "        #training=False\n",
        "        #mask=None\n",
        "        #model.evaluate(test_dataset , steps=test_steps)\n",
        "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        y_pred = model.predict(np.expand_dims(x, axis=0))\n",
        "        y_pred= y_pred[0]>0.5#if value of any pixel is gratern than 0.5 then it will work else it will be 0\n",
        "        h, w, _ = x.shape\n",
        "        white_line = np.ones((h, 10, 3)) * 255.0\n",
        "\n",
        "        opt = tf.keras.optimizers.Adam(lr)\n",
        "        metrics = [\"acc\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), iou]\n",
        "        model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)\n",
        "\n",
        "        all_images = [\n",
        "            x*255.0 , white_line,\n",
        "            mask_parse(y), white_line,\n",
        "            mask_parse(y_pred)*255.0\n",
        "        ]\n",
        "        image = np.concatenate(all_images, axis=1)\n",
        "        cv2.imwrite(f\"/content/drive/MyDrive/results/{i}.png\", image)\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "3_LxpLH_4fig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d63827-6bf5-4665-bf4a-739f29751447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320 40 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 606ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 1/40 [00:00<00:34,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 844ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 2/40 [00:01<00:35,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 856ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 3/40 [00:02<00:35,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 863ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 4/40 [00:03<00:35,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 785ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 5/40 [00:04<00:33,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 548ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 6/40 [00:05<00:28,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 549ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 7/40 [00:06<00:25,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 523ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 8/40 [00:06<00:23,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 543ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 9/40 [00:07<00:21,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 528ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 10/40 [00:07<00:20,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 555ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 11/40 [00:08<00:19,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 586ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 12/40 [00:09<00:18,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 605ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 13/40 [00:10<00:19,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 542ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 14/40 [00:10<00:18,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 528ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 15/40 [00:11<00:16,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 533ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 16/40 [00:12<00:16,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 554ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 17/40 [00:12<00:15,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 525ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 18/40 [00:13<00:14,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 512ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 19/40 [00:14<00:13,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 543ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 20/40 [00:14<00:13,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 839ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 21/40 [00:15<00:14,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 853ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 22/40 [00:16<00:14,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 849ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 23/40 [00:17<00:14,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 794ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 24/40 [00:18<00:14,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 25/40 [00:20<00:15,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 548ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 26/40 [00:20<00:12,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 505ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 27/40 [00:21<00:10,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 553ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 28/40 [00:21<00:09,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 541ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 29/40 [00:22<00:08,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 529ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 30/40 [00:23<00:07,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 515ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 31/40 [00:23<00:06,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 508ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 32/40 [00:24<00:05,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 544ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 33/40 [00:25<00:04,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 513ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 34/40 [00:25<00:03,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 495ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 35/40 [00:26<00:03,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 514ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 36/40 [00:26<00:02,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 506ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 37/40 [00:27<00:01,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 494ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 38/40 [00:28<00:01,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 542ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 39/40 [00:28<00:00,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 858ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:29<00:00,  1.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRADCAM.PY"
      ],
      "metadata": {
        "id": "lDxLmuh20Y3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow numpy matplotlib opencv-python-headless"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOCMxv1H08a6",
        "outputId": "70d8f24a-5299-4027-bdeb-0422797e792e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.7)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tqdm import tqdm\n",
        "with CustomObjectScope({'iou': iou}):\n",
        "        model = VGG16(tf.keras.models.load_model(\"/content/drive/MyDrive/files/model.h5\"))\n",
        "# load the original image from disk (in OpenCV format) and then\n",
        "# resize the image to its target dimensions\n",
        "orig = cv2.imread(\"/content/drive/MyDrive/images/0004a718-546c-41c2-9c69-c4685093a039.jpg\")\n",
        "resized = cv2.resize(orig, (224, 224))\n",
        "# load the input image from disk (in Keras/TensorFlow format) and\n",
        "# preprocess it\n",
        "image = load_img(\"/content/drive/MyDrive/images/0004a718-546c-41c2-9c69-c4685093a039.jpg\", target_size=(224, 224))\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = imagenet_utils.preprocess_input(image)\n",
        "# use the network to make predictions on the input imag and find\n",
        "# the class label index with the largest corresponding probability\n",
        "preds = model.predict(image)\n",
        "i = np.argmax(preds[0])\n",
        "# decode the ImageNet predictions to obtain the human-readable label\n",
        "decoded = imagenet_utils.decode_predictions(preds)\n",
        "(imagenetID, label, prob) = decoded[0][0]\n",
        "label = \"{}: {:.2f}%\".format(label, prob * 100)\n",
        "#print(\"[INFO] {}\".format(label))\n",
        "class GradCAM:\n",
        "    def __init__(self, model, classIdx, layerName=None):\n",
        "        # store the model, the class index used to measure the class\n",
        "        # activation map, and the layer to be used when visualizing\n",
        "        # the class activation map\n",
        "        self.model = model\n",
        "        self.classIdx = classIdx\n",
        "        self.layerName = layerName\n",
        "\n",
        "        # if the layer name is None, attempt to automatically find\n",
        "        # the target output layer\n",
        "        if self.layerName is None:\n",
        "            self.layerName = self.find_target_layer()\n",
        "\n",
        "    def find_target_layer(self):\n",
        "        # attempt to find the final convolutional layer in the network\n",
        "        # by looping over the layers of the network in reverse order\n",
        "        for layer in reversed(self.model.layers):\n",
        "            # check to see if the layer has a 4D output\n",
        "            if len(layer.output.shape) == 4:\n",
        "                return layer.name\n",
        "\n",
        "        # otherwise, we could not find a 4D layer so the GradCAM\n",
        "        # algorithm cannot be applied\n",
        "        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
        "\n",
        "    def compute_heatmap(self, image, eps=1e-8):\n",
        "        # construct our gradient model by supplying (1) the inputs\n",
        "        # to our pre-trained model, (2) the output of the (presumably)\n",
        "        # final 4D layer in the network, and (3) the output of the\n",
        "        # softmax activations from the model\n",
        "        gradModel = Model(inputs=[self.model.inputs], outputs= [self.model.get_layer(self.layerName).output, self.model.output])\n",
        "\n",
        "        # record operations for automatic differentiation\n",
        "        with tf.GradientTape() as tape:\n",
        "            # cast the image tensor to a float-32 data type, pass the\n",
        "            # image through the gradient model, and grab the loss\n",
        "            # associated with the specific class index\n",
        "            inputs = tf.cast(image, tf.float32)\n",
        "            (convOutputs, predictions) = gradModel(inputs)\n",
        "            loss = predictions[:, self.classIdx]\n",
        "\n",
        "        # use automatic differentiation to compute the gradients\n",
        "        grads = tape.gradient(loss, convOutputs)\n",
        "\n",
        "        # compute the guided gradients\n",
        "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
        "        castGrads = tf.cast(grads > 0, \"float32\")\n",
        "        guidedGrads = castConvOutputs * castGrads * grads\n",
        "\n",
        "        # the convolution and guided gradients have a batch dimension\n",
        "        # (which we don't need) so let's grab the volume itself and\n",
        "        # discard the batch\n",
        "        convOutputs = convOutputs[0]\n",
        "        guidedGrads = guidedGrads[0]\n",
        "\n",
        "        # compute the average of the gradient values, and using them\n",
        "        # as weights, compute the ponderation of the filters with\n",
        "        # respect to the weights\n",
        "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
        "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
        "\n",
        "        # grab the spatial dimensions of the input image and resize\n",
        "        # the output class activation map to match the input image\n",
        "        # dimensions\n",
        "        (w, h) = (image.shape[2], image.shape[1])\n",
        "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
        "\n",
        "        # normalize the heatmap such that all values lie in the range\n",
        "        # [0, 1], scale the resulting values to the range [0, 255],\n",
        "        # and then convert to an unsigned 8-bit integer\n",
        "        numer = heatmap - np.min(heatmap)\n",
        "        denom = (heatmap.max() - heatmap.min()) + eps\n",
        "        heatmap = numer / denom\n",
        "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
        "\n",
        "        # return the resulting heatmap to the calling function\n",
        "        return heatmap\n",
        "\n",
        "    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n",
        "        colormap=cv2.COLORMAP_JET):\n",
        "        # apply the supplied color map to the heatmap and then\n",
        "        # overlay the heatmap on the input image\n",
        "        heatmap = cv2.applyColorMap(heatmap, colormap)\n",
        "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
        "\n",
        "        # return a 2-tuple of the color mapped heatmap and the output,\n",
        "        # overlaid image\n",
        "        return (heatmap, output)\n",
        "# initialize our gradient class activation map and build the heatmap\n",
        "cam = GradCAM(model, i)\n",
        "heatmap = cam.compute_heatmap(image)\n",
        "\n",
        "# resize the resulting heatmap to the original input image dimensions\n",
        "# and then overlay heatmap on top of the image\n",
        "heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n",
        "(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)\n",
        "\n",
        "# draw the predicted label on the output image\n",
        "cv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)\n",
        "cv2.putText(output, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "# display the original image and resulting heatmap and output image\n",
        "# to our screen\n",
        "#output = np.concatenate([orig, heatmap, output], axis=1)\n",
        "output = np.vstack([orig, heatmap, output])\n",
        "output = imutils.resize(output, height=700)\n",
        "cv2.imwrite(f\"/content/drive/MyDrive/gradcam/{i}.png\", output)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "BFCHQR8hBAMu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a64b8dc3-0df9-4bdb-8c99-aa6a7d3ff9af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d48ebe757d3f>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'iou'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/files/model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# load the original image from disk (in OpenCV format) and then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iou' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}